{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/troyapaytan/tpportfolio/blob/main/FNN_SVM_RF%20COMPARISON/FNN_SVM_RF_TERM_PROJECT_CS171.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Marc Jason M. Chan\n",
        "\n",
        "Troy Andrei Paytan"
      ],
      "metadata": {
        "id": "_kqOGaDpbPYV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXV4yRUKIBtz",
        "outputId": "f37bc5b1-75c7-49f4-ec31-2b3b1601adfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Import necessary libraries\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import dlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import PIL.Image\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 1 - Dataset Labeling##"
      ],
      "metadata": {
        "id": "zoX7gDy-WqON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset and label each instance with its corresponding emotion class. For example, if an image represents a happy expression, label it as 'happy.' Similarly, label other images with their respective emotion classes."
      ],
      "metadata": {
        "id": "dDCaWzR_V_rG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/MyDrive/Module 3 dataset/train\"  # Replace this with the path to your main folder\n",
        "emotion_classes = [\"happy\", \"disgust\", \"fear\", \"surprise\", \"angry\", \"neutral\", \"sad\"]\n",
        "\n",
        "# Initialize lists to hold images and labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for emotion_class in emotion_classes:\n",
        "    class_dir = os.path.join(data_dir, emotion_class)\n",
        "    for image_file in os.listdir(class_dir):\n",
        "        image_path = os.path.join(class_dir, image_file)\n",
        "        image = Image.open(image_path)\n",
        "        images.append(image)\n",
        "        labels.append(emotion_class)"
      ],
      "metadata": {
        "id": "am0X-UKQJF-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of images:\", len(images))\n",
        "print(\"Number of labels:\", len(labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcrh6dCDKFsM",
        "outputId": "b2f78f98-0447-40a8-c678-a7916ad73fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images: 420\n",
            "Number of labels: 420\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 2- Feature Extraction##\n",
        "\n",
        "We will use OpenCV's built-in face detector (Haar Cascade) and facial landmark detector to extract the necessary facial features."
      ],
      "metadata": {
        "id": "LOhiiaLgWygh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained face detector and facial landmark detector\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "landmark_model = \"/content/drive/MyDrive/shape_predictor_68_face_landmarks.dat\"  # Replace this with the path to the facial landmark model\n",
        "\n",
        "# Load the facial landmark detector model\n",
        "predictor = dlib.shape_predictor(landmark_model)\n",
        "\n",
        "# Function to detect facial landmarks\n",
        "def detect_landmarks(image, circle_size=1, circle_color=(0, 0, 255)):\n",
        "    image_copy = image.copy()  # Make a copy of the original image\n",
        "    gray = cv2.cvtColor(image_copy, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        face_roi = image_copy[y:y + h, x:x + w]\n",
        "        gray_roi = gray[y:y + h, x:x + w]\n",
        "\n",
        "        # Detect facial landmarks\n",
        "        landmarks = predictor(gray_roi, dlib.rectangle(0, 0, w, h))\n",
        "\n",
        "        # Convert landmarks to numpy array\n",
        "        landmarks_np = np.array([[p.x, p.y] for p in landmarks.parts()])\n",
        "\n",
        "        # Draw facial landmarks on the image copy\n",
        "        for (x, y) in landmarks_np:\n",
        "            cv2.circle(image_copy, (x, y), circle_size, circle_color, -1)\n",
        "\n",
        "    return image_copy\n",
        "\n"
      ],
      "metadata": {
        "id": "28uEaX_heM92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of the code above is to load a pre-trained face detection model and a facial landmark detection model. It defines a function called detect_landmarks that takes an input image and detects facial landmarks using the loaded models. The function identifies faces in the image using the face detection model, extracts facial regions of interest, applies the facial landmark detection model to those regions, and then draws circles at the detected landmarks on a copy of the input image. The function returns the modified image with visualized facial landmarks. This code is useful for extracting and visualizing facial landmarks on input images, which is a crucial step in various facial analysis tasks, such as emotion recognition.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i7TZTUivb4iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  # Extract and visualize facial landmarks for the first image in the dataset\n",
        "  image_path = \"/content/drive/MyDrive/Module 3 dataset/train/happy/165.jpg\"\n",
        "  image = cv2.imread(image_path)\n",
        "\n",
        "  # Adjust the precision of plotting facial landmarks by modifying circle_size and circle_color\n",
        "  landmarked_image = detect_landmarks(image, circle_size=1, circle_color=(255, 0, 0))\n",
        "\n",
        "  # Display the original image using matplotlib\n",
        "  plt.figure(figsize=(8, 4))\n",
        "  plt.subplot(121)\n",
        "  plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "  plt.title(\"Original Image\")\n",
        "  plt.axis(\"off\")\n",
        "\n",
        "  # Display the image with facial landmarks using matplotlib\n",
        "  plt.subplot(122)\n",
        "  plt.imshow(cv2.cvtColor(landmarked_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.title(\"Image with Facial Landmarks\")\n",
        "  plt.axis(\"off\")\n",
        "\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "5oriiZozfZYh",
        "outputId": "e710fdd3-8581-4413-80a9-fe0e1fabe72a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Facial landmarks was extracted and visualized, specifically for the emotion of \"happy,\" from an image in a dataset. It uses OpenCV to read and process the image, detects facial landmarks using the detect_landmarks function, adjusts the precision of landmark visualization, and then displays both the original image and the image with highlighted facial landmarks side by side.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "HAOVioC4X58d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 3 - Dataset Splitting##\n",
        "\n",
        "Split the dataset into two parts: training and test sets. Use a stratified sampling technique to ensure that each emotion class is proportionally represented in both sets. 75-25 ratio was used for training and testing data"
      ],
      "metadata": {
        "id": "1b39ENAilObq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training (75%) and test (25%) sets with stratified sampling\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.25, random_state=42, stratify=labels)\n",
        "\n",
        "# Print the number of samples in the training and test sets\n",
        "print(\"Number of samples in the training set:\", len(train_images))\n",
        "print(\"Number of samples in the test set:\", len(test_images))\n",
        "\n"
      ],
      "metadata": {
        "id": "VPlHA5RWlXne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60ec6cb8-8a66-4658-aa40-9336a9134fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in the training set: 315\n",
            "Number of samples in the test set: 105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_pil_image_to_numpy_array(image):\n",
        "    image_np = np.array(image, dtype=np.uint8)\n",
        "    image_np = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n",
        "    return image_np\n",
        "\n",
        "images = np.array([convert_pil_image_to_numpy_array(image) for image in train_images])"
      ],
      "metadata": {
        "id": "nztwFEi5S43K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 4: Model Development"
      ],
      "metadata": {
        "id": "ejIsBws-wwPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before training the models, preprocessing may be needed for the extracted facial landmarks or features and convert them into a suitable format for training the classifiers. Typically, you would flatten the features and create a feature matrix as input for the classifiers"
      ],
      "metadata": {
        "id": "I8OhKWD4VAH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = np.array([np.array(image).flatten() for image in train_images])\n",
        "test_features = np.array([np.array(image).flatten() for image in test_images])\n"
      ],
      "metadata": {
        "id": "8lzJjaK_w08K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train Support Vector Machine (SVM) Classifier##\n",
        "SVM is a powerful classification algorithm that can be effective for image-based tasks. We'll use scikit-learn's SVC class for training."
      ],
      "metadata": {
        "id": "DyOn-UNfUUja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize the SVM classifier\n",
        "svm_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "\n",
        "# Train the SVM classifier on the training data\n",
        "svm_classifier.fit(train_features, train_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "uVDw2iEgUhBz",
        "outputId": "4a3e9623-7dd8-49f3-f113-faba74b92ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear', random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train Random Forest Classifier\n",
        "Random Forest is an ensemble learning method that can handle non-linear relationships between features. We'll use scikit-learn's RandomForestClassifier for training."
      ],
      "metadata": {
        "id": "9H8BAhOgYj7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Random Forest classifier on the training data\n",
        "rf_classifier.fit(train_features, train_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "-3yw8VBWYkNP",
        "outputId": "b453bf07-32c3-40b7-bfdf-f3ae019f989d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train Feedforward Neural Network (FNN)\n",
        "\n",
        "A Feedforward Neural Network, also known as a Multilayer Perceptron (MLP), is a type of artificial neural network that consists of an input layer, one or more hidden layers, and an output layer. It can be suitable for small datasets and simpler tasks like emotion recognition from handcrafted features."
      ],
      "metadata": {
        "id": "Tpuvx4Ccaye8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we use LabelEncoder to convert the string labels into integer-encoded labels. Then, we use OneHotEncoder to one-hot encode the integer-encoded labels. This process ensures that your categorical labels are transformed into a suitable format for training the FNN."
      ],
      "metadata": {
        "id": "VUfx1yRjZywc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "# Encode the labels into integers using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "test_labels_encoded = label_encoder.transform(test_labels)\n",
        "\n",
        "# One-hot encode the integer labels using OneHotEncoder\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "train_labels_one_hot = onehot_encoder.fit_transform(train_labels_encoded.reshape(-1, 1))\n",
        "test_labels_one_hot = onehot_encoder.transform(test_labels_encoded.reshape(-1, 1))\n",
        "\n",
        "# Now `train_labels_one_hot` and `test_labels_one_hot` are one-hot encoded label matrices\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiam8USJadai",
        "outputId": "815247cb-5c05-4cae-9d47-4f5d433db2f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Normalize the features (optional but recommended for FNN)\n",
        "scaler = StandardScaler()\n",
        "train_features_normalized = scaler.fit_transform(train_features)\n",
        "test_features_normalized = scaler.transform(test_features)\n",
        "\n",
        "# Initialize the FNN classifier\n",
        "fnn_classifier = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42)\n",
        "\n",
        "# Train the FNN classifier on the training data\n",
        "fnn_classifier.fit(train_features_normalized, train_labels_one_hot)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Yd6gmt2DZzKi",
        "outputId": "52ae8330-d05b-4e99-b13f-e427c9990326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(100, 50), random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(100, 50), random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(100, 50), random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 6: Model Testing\n",
        "\n",
        " We will evaluate the performance of the trained classifiers (SVM, Random Forest, and FNN) on the test set and analyze the results."
      ],
      "metadata": {
        "id": "cSC8hnSwcapi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,precision_score, recall_score, f1_score\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "XAiWzBoZftup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Support Vector Machine (SVM) Classifier:\n"
      ],
      "metadata": {
        "id": "Df4et7cGcx93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Support Vector Machine (SVM) Classifier\n",
        "svm_predictions = svm_classifier.predict(test_features)\n",
        "svm_accuracy = accuracy_score(test_labels, svm_predictions)\n",
        "svm_precision = precision_score(test_labels, svm_predictions, average='weighted')\n",
        "svm_recall = recall_score(test_labels, svm_predictions, average='weighted')\n",
        "svm_f1 = f1_score(test_labels, svm_predictions, average='weighted')\n",
        "svm_conf_matrix = confusion_matrix(test_labels, svm_predictions, labels=emotion_classes)\n",
        "\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Precision:\", svm_precision)\n",
        "print(\"SVM Recall:\", svm_recall)\n",
        "print(\"SVM F1-score:\", svm_f1)\n",
        "print(\"SVM Confusion Matrix:\")\n",
        "print(svm_conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUO9nKxUc4Oj",
        "outputId": "adf23aaf-e4a6-49cc-f58a-4c2e8d728c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.23809523809523808\n",
            "SVM Precision: 0.23847933112638994\n",
            "SVM Recall: 0.23809523809523808\n",
            "SVM F1-score: 0.23488050885866957\n",
            "SVM Confusion Matrix:\n",
            "[[4 3 3 1 3 1 0]\n",
            " [1 2 4 0 4 3 1]\n",
            " [3 6 4 2 0 0 0]\n",
            " [3 1 2 4 1 1 3]\n",
            " [2 2 2 1 4 3 1]\n",
            " [1 2 0 0 4 6 2]\n",
            " [2 2 0 3 4 3 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Random Forest Classifier:"
      ],
      "metadata": {
        "id": "AA2wKG6Ic-ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Random Forest Classifier\n",
        "rf_predictions = rf_classifier.predict(test_features)\n",
        "rf_accuracy = accuracy_score(test_labels, rf_predictions)\n",
        "rf_precision = precision_score(test_labels, rf_predictions, average='weighted')\n",
        "rf_recall = recall_score(test_labels, rf_predictions, average='weighted')\n",
        "rf_f1 = f1_score(test_labels, rf_predictions, average='weighted')\n",
        "rf_conf_matrix = confusion_matrix(test_labels, rf_predictions, labels=emotion_classes)\n",
        "\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
        "print(\"Random Forest Precision:\", rf_precision)\n",
        "print(\"Random Forest Recall:\", rf_recall)\n",
        "print(\"Random Forest F1-score:\", rf_f1)\n",
        "print(\"Random Forest Confusion Matrix:\")\n",
        "print(rf_conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7oMglbYdCb_",
        "outputId": "8942ce52-3ac6-4da4-d974-b1f3c8f72c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.18095238095238095\n",
            "Random Forest Precision: 0.1774467362702657\n",
            "Random Forest Recall: 0.18095238095238095\n",
            "Random Forest F1-score: 0.17254554004554004\n",
            "Random Forest Confusion Matrix:\n",
            "[[5 3 2 0 2 2 1]\n",
            " [5 3 2 1 2 1 1]\n",
            " [4 3 1 4 2 0 1]\n",
            " [4 2 1 2 2 1 3]\n",
            " [4 2 1 0 4 1 3]\n",
            " [1 3 1 0 6 3 1]\n",
            " [2 1 1 4 4 2 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Feedforward Neural Network (FNN) Classifier:"
      ],
      "metadata": {
        "id": "RX0Wc-rddHJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode one-hot encoded predictions to integer labels\n",
        "fnn_predictions_decoded = np.argmax(fnn_predictions, axis=1)\n",
        "\n",
        "# Test Feedforward Neural Network (FNN) Classifier\n",
        "fnn_accuracy = accuracy_score(test_labels_encoded, fnn_predictions_decoded)\n",
        "fnn_precision = precision_score(test_labels_encoded, fnn_predictions_decoded, average='weighted')\n",
        "fnn_recall = recall_score(test_labels_encoded, fnn_predictions_decoded, average='weighted')\n",
        "fnn_f1 = f1_score(test_labels_encoded, fnn_predictions_decoded, average='weighted')\n",
        "fnn_conf_matrix = confusion_matrix(test_labels_encoded, fnn_predictions_decoded, labels=range(len(emotion_classes)))\n",
        "\n",
        "print(\"FNN Accuracy:\", fnn_accuracy)\n",
        "print(\"FNN Precision:\", fnn_precision)\n",
        "print(\"FNN Recall:\", fnn_recall)\n",
        "print(\"FNN F1-score:\", fnn_f1)\n",
        "print(\"FNN Confusion Matrix:\")\n",
        "print(fnn_conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lro-gCpAdKHR",
        "outputId": "ff2d295a-07d1-43dc-9fea-af1f17e85bf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FNN Accuracy: 0.21904761904761905\n",
            "FNN Precision: 0.3584767240229425\n",
            "FNN Recall: 0.21904761904761905\n",
            "FNN F1-score: 0.2151135718021572\n",
            "FNN Confusion Matrix:\n",
            "[[ 9  2  0  2  0  1  1]\n",
            " [11  2  1  0  0  1  0]\n",
            " [10  2  1  1  0  0  1]\n",
            " [11  1  0  3  0  0  0]\n",
            " [10  0  0  1  3  1  0]\n",
            " [11  1  0  0  1  1  1]\n",
            " [ 6  1  0  2  2  0  4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compare Results and Analyze:**\n",
        "\n",
        "we display the calculated metrics (accuracy, precision, recall, F1-score) and confusion matrices for each classifier: SVM, Random Forest, and FNN. We also determine the best classifier based on the highest accuracy.\n",
        "\n",
        "Now, analyze the results based on these metrics and matrices:\n",
        "\n",
        "**Accuracy:** The accuracy metric tells you how well the classifier performs overall. A higher accuracy is better, but it's important to consider other metrics as well, especially for imbalanced datasets.\n",
        "\n",
        "**Precision:** Precision measures the ratio of correctly predicted positive observations to the total predicted positives. It's a useful metric when false positives are costly.\n",
        "\n",
        "**Recall:** Recall, also known as sensitivity or true positive rate, measures the ratio of correctly predicted positive observations to the all observations in the actual class. It's a useful metric when false negatives are costly.\n",
        "\n",
        "**F1-score:** The F1-score is the harmonic mean of precision and recall. It provides a balance between precision and recall, making it a good metric for imbalanced datasets.\n",
        "\n",
        "**Confusion Matrix:** The confusion matrix gives a detailed view of the classifier's performance for each emotion class. It shows the true positive, true negative, false positive, and false negative predictions for each class."
      ],
      "metadata": {
        "id": "TnsJBqWbdbwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare Results and Analyze\n",
        "print(\"SVM Classifier:\")\n",
        "print(\"Accuracy:\", svm_accuracy)\n",
        "print(\"Precision:\", svm_precision)\n",
        "print(\"Recall:\", svm_recall)\n",
        "print(\"F1-score:\", svm_f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(svm_conf_matrix)\n",
        "print()\n",
        "\n",
        "print(\"Random Forest Classifier:\")\n",
        "print(\"Accuracy:\", rf_accuracy)\n",
        "print(\"Precision:\", rf_precision)\n",
        "print(\"Recall:\", rf_recall)\n",
        "print(\"F1-score:\", rf_f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(rf_conf_matrix)\n",
        "print()\n",
        "\n",
        "print(\"Feedforward Neural Network (FNN) Classifier:\")\n",
        "print(\"Accuracy:\", fnn_accuracy)\n",
        "print(\"Precision:\", fnn_precision)\n",
        "print(\"Recall:\", fnn_recall)\n",
        "print(\"F1-score:\", fnn_f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(fnn_conf_matrix)\n",
        "print()\n",
        "\n",
        "# Compare the accuracies of the classifiers\n",
        "best_accuracy = max(svm_accuracy, rf_accuracy, fnn_accuracy)\n",
        "best_classifier = None\n",
        "\n",
        "if best_accuracy == svm_accuracy:\n",
        "    best_classifier = \"SVM\"\n",
        "elif best_accuracy == rf_accuracy:\n",
        "    best_classifier = \"Random Forest\"\n",
        "else:\n",
        "    best_classifier = \"FNN\"\n",
        "\n",
        "print(\"Best Classifier:\", best_classifier)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_LhBH_addHm",
        "outputId": "8002719f-f6dd-41d1-ac10-505afdc477aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Classifier:\n",
            "Accuracy: 0.23809523809523808\n",
            "Precision: 0.23847933112638994\n",
            "Recall: 0.23809523809523808\n",
            "F1-score: 0.23488050885866957\n",
            "Confusion Matrix:\n",
            "[[4 3 3 1 3 1 0]\n",
            " [1 2 4 0 4 3 1]\n",
            " [3 6 4 2 0 0 0]\n",
            " [3 1 2 4 1 1 3]\n",
            " [2 2 2 1 4 3 1]\n",
            " [1 2 0 0 4 6 2]\n",
            " [2 2 0 3 4 3 1]]\n",
            "\n",
            "Random Forest Classifier:\n",
            "Accuracy: 0.18095238095238095\n",
            "Precision: 0.1774467362702657\n",
            "Recall: 0.18095238095238095\n",
            "F1-score: 0.17254554004554004\n",
            "Confusion Matrix:\n",
            "[[5 3 2 0 2 2 1]\n",
            " [5 3 2 1 2 1 1]\n",
            " [4 3 1 4 2 0 1]\n",
            " [4 2 1 2 2 1 3]\n",
            " [4 2 1 0 4 1 3]\n",
            " [1 3 1 0 6 3 1]\n",
            " [2 1 1 4 4 2 1]]\n",
            "\n",
            "Feedforward Neural Network (FNN) Classifier:\n",
            "Accuracy: 0.21904761904761905\n",
            "Precision: 0.3584767240229425\n",
            "Recall: 0.21904761904761905\n",
            "F1-score: 0.2151135718021572\n",
            "Confusion Matrix:\n",
            "[[ 9  2  0  2  0  1  1]\n",
            " [11  2  1  0  0  1  0]\n",
            " [10  2  1  1  0  0  1]\n",
            " [11  1  0  3  0  0  0]\n",
            " [10  0  0  1  3  1  0]\n",
            " [11  1  0  0  1  1  1]\n",
            " [ 6  1  0  2  2  0  4]]\n",
            "\n",
            "Best Classifier: SVM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Support Vector Machine (SVM) Classifier:**\n",
        "\n",
        ">The SVM classifier achieves an accuracy of approximately 23.81%. Precision, recall, and F1-score are also around the same value. The confusion matrix shows that the classifier has varying performance across different emotion classes. For instance, it has some difficulty distinguishing between emotions in some cases, as evident from non-diagonal values in the confusion matrix.\n",
        "\n",
        "**Random Forest Classifier:**\n",
        ">The Random Forest classifier achieves an accuracy of around 18.10%. The precision, recall, and F1-score are also in a similar range. The confusion matrix suggests that the classifier faces challenges in correctly classifying certain emotions, with higher misclassifications for some classes.\n",
        "\n",
        "**Feedforward Neural Network (FNN) Classifier:**\n",
        ">The FNN classifier achieves an accuracy of about 21.90%. It displays relatively higher precision compared to the other two classifiers, which suggests a better balance between true positives and false positives. However, the recall and F1-score are not significantly better than the other classifiers. The confusion matrix implies that the FNN classifier faces challenges in accurately predicting certain emotion classes.\n",
        "\n",
        "Comparison and Analysis:\n",
        "\n",
        "\n",
        "*   In terms of accuracy, the SVM classifier has the highest accuracy among the three classifiers.\n",
        "*   However, accuracy alone might not provide a complete picture, especially for imbalanced datasets where some emotion classes have fewer samples. This is evident from the confusion matrices, where some classes have more misclassifications than others.\n",
        "\n",
        "* The precision, recall, and F1-score metrics are relatively low for all classifiers, indicating that there is room for improvement in distinguishing between different emotions.\n",
        "* The choice of the best classifier (SVM) is based solely on accuracy in this case. It's important to consider other metrics and the nature of misclassifications when selecting the best classifier for your specific use case.\n",
        "* The results suggest that the dataset might be challenging for the classifiers, possibly due to the limited amount of data or the complexity of distinguishing between certain emotions."
      ],
      "metadata": {
        "id": "Lj78MJFOhQWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**References:**\n",
        "\n",
        "1. https://www.analyticsvidhya.com/blog/2022/10/face-detection-using-haar-cascade-using-python/\n",
        "\n",
        "2. https://github.com/italojs/facial-landmarks-recognition/blob/master/shape_predictor_68_face_landmarks.dat\n",
        "\n",
        "3. https://www.kaggle.com/code/prashant111/svm-classifier-tutorial\n",
        "\n",
        "4. https://www.kaggle.com/code/prashant111/random-forest-classifier-tutorial\n",
        "5. https://www.kaggle.com/code/praanj/basics-of-feed-forward-neural-networks\n"
      ],
      "metadata": {
        "id": "DrPvJRpE2ngB"
      }
    }
  ]
}